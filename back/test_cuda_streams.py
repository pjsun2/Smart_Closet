"""
CUDA Streams ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸
=============================
ìˆœì°¨ ì²˜ë¦¬ vs CUDA Streams ë³‘ë ¬ ì²˜ë¦¬ ì„±ëŠ¥ ë¹„êµ
"""

import sys
import os
import time
import numpy as np

current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, os.path.join(current_dir, 'fit'))

from virtual_fitting import RTMPoseVirtualFitting
import torch

def quick_benchmark(use_cuda_streams=True):
    """ë¹ ë¥¸ ì„±ëŠ¥ ì¸¡ì •"""
    print(f"\n{'='*70}")
    print(f"Testing: {'CUDA Streams (Parallel)' if use_cuda_streams else 'Sequential Processing'}")
    print(f"{'='*70}")
    
    # VirtualFitting ì´ˆê¸°í™”
    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
    vf = RTMPoseVirtualFitting(
        cloth_image_path=os.path.join(current_dir, 'fit', 'input', 'cloth.jpg'),
        device=device
    )
    
    # í…ŒìŠ¤íŠ¸ í”„ë ˆì„ ìƒì„±
    test_frames = []
    for i in range(30):
        frame = np.random.randint(0, 255, (720, 1280, 3), dtype=np.uint8)
        test_frames.append(frame)
    
    print(f"[Test] Processing {len(test_frames)} frames...")
    
    # ì›Œë°ì—…
    for i in range(3):
        _ = vf.process_frame(test_frames[i], show_skeleton=False, use_warp=False)
    
    # ì‹¤ì œ ì¸¡ì •
    start_time = time.time()
    for frame in test_frames:
        _ = vf.process_frame(frame, show_skeleton=False, use_warp=False)
    elapsed = time.time() - start_time
    
    fps = len(test_frames) / elapsed
    
    print(f"[Result] Elapsed: {elapsed:.2f}s")
    print(f"[Result] FPS: {fps:.2f}")
    
    vf.stop_inference_thread()
    
    return fps

if __name__ == "__main__":
    print("\n" + "ğŸš€"*35)
    print("CUDA Streams Performance Test")
    print("ğŸš€"*35)
    
    # CUDA Streams í™œì„±í™” ìƒíƒœ í…ŒìŠ¤íŠ¸
    fps_parallel = quick_benchmark(use_cuda_streams=True)
    
    print(f"\n{'='*70}")
    print(f"Results Summary")
    print(f"{'='*70}")
    print(f"CUDA Streams (Parallel): {fps_parallel:.2f} FPS")
    print(f"\nâœ… Test Complete!")
    print(f"{'='*70}\n")
