"""
ê°€ìƒ í”¼íŒ… ì‹œìŠ¤í…œ ì¢…í•© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
- í•´ìƒë„ë³„ ì„±ëŠ¥ ë¹„êµ (480p, 720p, 1080p)
- GPU ì‚¬ìš©ë¥  ë° ë©”ëª¨ë¦¬ ì¸¡ì •
- ë ˆì´í„´ì‹œ (ì§€ì—° ì‹œê°„) ë¶„ì„
- í”„ë ˆì„ ë“œë¡­ë¥  ì¸¡ì •
- ì²˜ë¦¬ ì‹œê°„ ë¶„í¬ (ì¶”ë¡ , ë Œë”ë§, ì „ì²´)
"""

import cv2
import numpy as np
import time
import sys
import os
import threading
import queue
import torch
import subprocess
import json
import matplotlib.pyplot as plt
from matplotlib import font_manager, rc
from collections import defaultdict

# í•œê¸€ í°íŠ¸ ì„¤ì •
try:
    plt.rcParams['font.family'] = 'Malgun Gothic'
    plt.rcParams['axes.unicode_minus'] = False
except:
    pass

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

from mmpose.apis import init_model, inference_topdown

class ComprehensivePerformanceTester:
    """ì¢…í•© ì„±ëŠ¥ í…ŒìŠ¤í„°"""
    
    def __init__(self, video_path, device='cuda:0'):
        self.video_path = video_path
        self.device = device
        
        # ë¹„ë””ì˜¤ ì •ë³´
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise FileNotFoundError(f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        
        self.video_fps = cap.get(cv2.CAP_PROP_FPS)
        self.total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        self.video_duration = self.total_frames / self.video_fps if self.video_fps > 0 else 0
        cap.release()
        
        print(f"[í…ŒìŠ¤íŠ¸] ë¹„ë””ì˜¤ ì •ë³´:")
        print(f"  - ì´ í”„ë ˆì„: {self.total_frames}")
        print(f"  - FPS: {self.video_fps:.2f}")
        print(f"  - ê¸¸ì´: {self.video_duration:.2f}ì´ˆ")
        
        # RTMPose ëª¨ë¸ ì´ˆê¸°í™”
        config_file = os.path.join(current_dir, 'models', 'rtmpose-s_8xb256-420e_aic-coco-256x192.py')
        checkpoint_file = os.path.join(current_dir, 'models', 'rtmpose-s_simcc-aic-coco_pt-aic-coco_420e-256x192-fcb2599b_20230126.pth')
        
        print(f"[í…ŒìŠ¤íŠ¸] ëª¨ë¸ ë¡œë”© ì¤‘... (device: {device})")
        self.model = init_model(config_file, checkpoint_file, device=device)
        self.model.eval()
        
        # GPU ì›Œë°ì—…
        if torch.cuda.is_available() and 'cuda' in device:
            print("[í…ŒìŠ¤íŠ¸] GPU ì›Œë°ì—… ì¤‘...")
            torch.backends.cudnn.benchmark = True
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            
            dummy_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
            with torch.no_grad():
                _ = inference_topdown(self.model, dummy_image)
            torch.cuda.empty_cache()
            print("[í…ŒìŠ¤íŠ¸] GPU ì›Œë°ì—… ì™„ë£Œ")
        
        # ìµœì  ì„¤ì • (ì´ì „ í…ŒìŠ¤íŠ¸ ê²°ê³¼)
        self.batch_size = 10
        self.queue_size = 22
        self.inference_scale = 0.65
        
        print(f"\n[í…ŒìŠ¤íŠ¸] í˜„ì¬ ì„¤ì •:")
        print(f"  - ë°°ì¹˜ í¬ê¸°: {self.batch_size}")
        print(f"  - í í¬ê¸°: {self.queue_size}")
        print(f"  - ì¶”ë¡  í•´ìƒë„: {int(self.inference_scale*100)}%")
    
    def get_gpu_stats(self):
        """GPU ì‚¬ìš©ë¥  ë° ë©”ëª¨ë¦¬ ì¸¡ì • (nvidia-smi)"""
        try:
            result = subprocess.run(
                ['nvidia-smi', '--query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu', 
                 '--format=csv,noheader,nounits'],
                capture_output=True,
                text=True,
                timeout=1
            )
            
            if result.returncode == 0:
                output = result.stdout.strip()
                gpu_util, mem_used, mem_total, temp = output.split(', ')
                return {
                    'gpu_utilization': float(gpu_util),
                    'memory_used': float(mem_used),
                    'memory_total': float(mem_total),
                    'temperature': float(temp)
                }
        except Exception as e:
            pass
        
        return None
    
    def test_resolution_performance(self, resolution_name, target_width, target_height):
        """íŠ¹ì • í•´ìƒë„ì—ì„œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print(f"\n{'='*70}")
        print(f"[í…ŒìŠ¤íŠ¸] {resolution_name} ({target_width}x{target_height}) í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print(f"{'='*70}")
        
        # í ì´ˆê¸°í™”
        inference_queue = queue.Queue(maxsize=self.queue_size)
        result_queue = queue.Queue(maxsize=self.queue_size // 2)
        running = True
        
        # ì„±ëŠ¥ ì¸¡ì • ë³€ìˆ˜
        frames_sent = 0
        frames_processed = 0
        frames_dropped = 0
        
        inference_times = []
        total_times = []
        gpu_stats_samples = []
        
        latencies = []  # í”„ë ˆì„ ì „ì†¡ â†’ ê²°ê³¼ ìˆ˜ì‹  ì‹œê°„
        frame_timestamps = {}  # í”„ë ˆì„ ID â†’ ì „ì†¡ ì‹œê°
        
        test_start_time = time.time()
        
        # ì¶”ë¡  ì›Œì»¤ ìŠ¤ë ˆë“œ
        def inference_worker():
            nonlocal frames_processed, inference_times
            
            while running:
                try:
                    batch_frames = []
                    frame_ids = []
                    frame_timeout = 0.015
                    
                    for i in range(self.batch_size):
                        try:
                            timeout = frame_timeout if i == 0 else frame_timeout * 0.5
                            frame_data = inference_queue.get(timeout=timeout)
                            
                            if frame_data is None:
                                return
                            
                            frame, frame_id = frame_data
                            batch_frames.append(frame)
                            frame_ids.append(frame_id)
                        except queue.Empty:
                            break
                    
                    if not batch_frames:
                        continue
                    
                    # ë°°ì¹˜ ì¶”ë¡ 
                    inference_start = time.time()
                    
                    try:
                        results_batch = []
                        if torch.cuda.is_available() and 'cuda' in self.device:
                            streams = [torch.cuda.Stream() for _ in range(len(batch_frames))]
                            stream_results = [None] * len(batch_frames)
                            
                            with torch.no_grad():
                                for i, (frame, stream) in enumerate(zip(batch_frames, streams)):
                                    with torch.cuda.stream(stream):
                                        stream_results[i] = inference_topdown(self.model, frame)
                            
                            torch.cuda.synchronize()
                            results_batch = stream_results
                        else:
                            with torch.no_grad():
                                for frame in batch_frames:
                                    result = inference_topdown(self.model, frame)
                                    results_batch.append(result)
                        
                        inference_end = time.time()
                        inference_time = inference_end - inference_start
                        inference_times.append(inference_time)
                        
                        frames_processed += len(batch_frames)
                        
                        # ê²°ê³¼ ì €ì¥ ë° ë ˆì´í„´ì‹œ ê³„ì‚°
                        result_timestamp = time.time()
                        for frame_id in frame_ids:
                            if frame_id in frame_timestamps:
                                latency = result_timestamp - frame_timestamps[frame_id]
                                latencies.append(latency)
                        
                        try:
                            result_queue.put_nowait(results_batch)
                        except queue.Full:
                            try:
                                result_queue.get_nowait()
                                result_queue.put_nowait(results_batch)
                            except:
                                pass
                    
                    except Exception as e:
                        print(f"[í…ŒìŠ¤íŠ¸] ì¶”ë¡  ì—ëŸ¬: {e}")
                        continue
                
                except Exception as e:
                    if running:
                        print(f"[í…ŒìŠ¤íŠ¸] ì›Œì»¤ ì—ëŸ¬: {e}")
                    continue
        
        # GPU ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ
        def gpu_monitor():
            while running:
                stats = self.get_gpu_stats()
                if stats:
                    gpu_stats_samples.append(stats)
                time.sleep(0.1)  # 100msë§ˆë‹¤ ìƒ˜í”Œë§
        
        # ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘
        worker_thread = threading.Thread(target=inference_worker, daemon=True)
        worker_thread.start()
        
        if torch.cuda.is_available():
            gpu_thread = threading.Thread(target=gpu_monitor, daemon=True)
            gpu_thread.start()
        
        # ë¹„ë””ì˜¤ ì½ê¸° ë° í”„ë ˆì„ ì „ì†¡
        cap = cv2.VideoCapture(self.video_path)
        
        if not cap.isOpened():
            print(f"[í…ŒìŠ¤íŠ¸] [ERROR] ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨")
            running = False
            return None
        
        frame_id = 0
        video_start_time = time.time()
        
        while running:
            loop_start = time.time()
            
            ret, frame = cap.read()
            if not ret:
                break
            
            # í˜„ì¬ ì‹œê°„ ì²´í¬
            elapsed = time.time() - video_start_time
            if elapsed >= self.video_duration:
                break
            
            # í•´ìƒë„ ì¡°ì •
            resized_frame = cv2.resize(frame, (target_width, target_height), interpolation=cv2.INTER_LINEAR)
            
            # ì¶”ë¡ ìš© ë‹¤ìš´ìŠ¤ì¼€ì¼
            inference_w = int(target_width * self.inference_scale)
            inference_h = int(target_height * self.inference_scale)
            inference_frame = cv2.resize(resized_frame, (inference_w, inference_h), interpolation=cv2.INTER_LINEAR)
            
            # íì— í”„ë ˆì„ ì¶”ê°€
            frame_timestamps[frame_id] = time.time()
            try:
                inference_queue.put_nowait((inference_frame, frame_id))
                frames_sent += 1
            except queue.Full:
                frames_dropped += 1
            
            frame_id += 1
            
            # ì „ì²´ ë£¨í”„ ì‹œê°„ ì¸¡ì •
            loop_time = time.time() - loop_start
            total_times.append(loop_time)
        
        # ì •ë¦¬
        running = False
        
        try:
            inference_queue.put(None, timeout=0.1)
        except:
            pass
        
        worker_thread.join(timeout=1.0)
        cap.release()
        
        # ê²°ê³¼ ê³„ì‚°
        test_elapsed = time.time() - test_start_time
        actual_fps = frames_processed / test_elapsed if test_elapsed > 0 else 0
        drop_rate = (frames_dropped / frames_sent * 100) if frames_sent > 0 else 0
        
        # GPU í†µê³„
        avg_gpu_util = 0
        avg_gpu_mem = 0
        avg_gpu_temp = 0
        
        if gpu_stats_samples:
            avg_gpu_util = np.mean([s['gpu_utilization'] for s in gpu_stats_samples])
            avg_gpu_mem = np.mean([s['memory_used'] for s in gpu_stats_samples])
            avg_gpu_temp = np.mean([s['temperature'] for s in gpu_stats_samples])
        
        # ë ˆì´í„´ì‹œ í†µê³„
        avg_latency = np.mean(latencies) * 1000 if latencies else 0
        p50_latency = np.percentile(latencies, 50) * 1000 if latencies else 0
        p95_latency = np.percentile(latencies, 95) * 1000 if latencies else 0
        p99_latency = np.percentile(latencies, 99) * 1000 if latencies else 0
        
        # ì¶”ë¡  ì‹œê°„ í†µê³„
        avg_inference = np.mean(inference_times) * 1000 if inference_times else 0
        p50_inference = np.percentile(inference_times, 50) * 1000 if inference_times else 0
        p95_inference = np.percentile(inference_times, 95) * 1000 if inference_times else 0
        p99_inference = np.percentile(inference_times, 99) * 1000 if inference_times else 0
        
        print(f"\n[í…ŒìŠ¤íŠ¸] {resolution_name} ê²°ê³¼:")
        print(f"  ğŸ“Š ì²˜ë¦¬ëŸ‰:")
        print(f"    - ì „ì†¡ í”„ë ˆì„: {frames_sent}")
        print(f"    - ì²˜ë¦¬ í”„ë ˆì„: {frames_processed}")
        print(f"    - ë“œë¡­ í”„ë ˆì„: {frames_dropped} ({drop_rate:.1f}%)")
        print(f"    - ì‹¤ì œ FPS: {actual_fps:.2f}")
        
        print(f"\n  â±ï¸ ë ˆì´í„´ì‹œ (í”„ë ˆì„ ì „ì†¡ â†’ ê²°ê³¼ ìˆ˜ì‹ ):")
        print(f"    - í‰ê· : {avg_latency:.2f}ms")
        print(f"    - P50: {p50_latency:.2f}ms")
        print(f"    - P95: {p95_latency:.2f}ms")
        print(f"    - P99: {p99_latency:.2f}ms")
        
        print(f"\n  ğŸ”§ ì¶”ë¡  ì‹œê°„ (ë°°ì¹˜ ì²˜ë¦¬):")
        print(f"    - í‰ê· : {avg_inference:.2f}ms")
        print(f"    - P50: {p50_inference:.2f}ms")
        print(f"    - P95: {p95_inference:.2f}ms")
        print(f"    - P99: {p99_inference:.2f}ms")
        
        if gpu_stats_samples:
            print(f"\n  ğŸ® GPU ì‚¬ìš©ë¥ :")
            print(f"    - í‰ê·  ì‚¬ìš©ë¥ : {avg_gpu_util:.1f}%")
            print(f"    - í‰ê·  ë©”ëª¨ë¦¬: {avg_gpu_mem:.0f}MB / {gpu_stats_samples[0]['memory_total']:.0f}MB")
            print(f"    - í‰ê·  ì˜¨ë„: {avg_gpu_temp:.1f}Â°C")
        
        return {
            'resolution': resolution_name,
            'width': target_width,
            'height': target_height,
            'frames_sent': frames_sent,
            'frames_processed': frames_processed,
            'frames_dropped': frames_dropped,
            'drop_rate': drop_rate,
            'fps': actual_fps,
            'latency_avg': avg_latency,
            'latency_p50': p50_latency,
            'latency_p95': p95_latency,
            'latency_p99': p99_latency,
            'inference_avg': avg_inference,
            'inference_p50': p50_inference,
            'inference_p95': p95_inference,
            'inference_p99': p99_inference,
            'gpu_util': avg_gpu_util,
            'gpu_mem': avg_gpu_mem,
            'gpu_temp': avg_gpu_temp,
            'latencies': latencies,
            'inference_times': inference_times,
            'gpu_stats': gpu_stats_samples
        }
    
    def run_comprehensive_test(self):
        """ì¢…í•© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"\n{'='*70}")
        print("[í…ŒìŠ¤íŠ¸] ì¢…í•© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print(f"{'='*70}\n")
        
        # í…ŒìŠ¤íŠ¸í•  í•´ìƒë„ë“¤
        resolutions = [
            ('480p', 854, 480),
            ('720p', 1280, 720),
            ('1080p', 1920, 1080),
        ]
        
        results = []
        
        for res_name, width, height in resolutions:
            result = self.test_resolution_performance(res_name, width, height)
            if result:
                results.append(result)
            
            # ë‹¤ìŒ í…ŒìŠ¤íŠ¸ ì „ GPU ì•ˆì •í™”
            time.sleep(1.0)
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        # ìµœì¢… ê²°ê³¼ ì¶œë ¥
        print(f"\n{'='*70}")
        print("[í…ŒìŠ¤íŠ¸] ì¢…í•© ê²°ê³¼ ë¹„êµ")
        print(f"{'='*70}")
        
        print(f"\n{'í•´ìƒë„':<10} | {'FPS':<8} | {'ë“œë¡­ë¥ ':<8} | {'ë ˆì´í„´ì‹œ(P95)':<12} | {'GPU ì‚¬ìš©ë¥ ':<10}")
        print(f"{'-'*70}")
        
        for r in results:
            print(f"{r['resolution']:<10} | {r['fps']:<8.2f} | {r['drop_rate']:<7.1f}% | "
                  f"{r['latency_p95']:<11.2f}ms | {r['gpu_util']:<9.1f}%")
        
        return results
    
    def visualize_comprehensive_results(self, results):
        """ì¢…í•© ê²°ê³¼ ì‹œê°í™”"""
        print(f"\n[í…ŒìŠ¤íŠ¸] ê²°ê³¼ ì‹œê°í™” ì¤‘...")
        
        if not results:
            print("[í…ŒìŠ¤íŠ¸] ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        fig = plt.figure(figsize=(18, 12))
        gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)
        
        resolutions = [r['resolution'] for r in results]
        
        # 1. FPS ë¹„êµ (ë§‰ëŒ€ ê·¸ë˜í”„)
        ax1 = fig.add_subplot(gs[0, 0])
        fps_values = [r['fps'] for r in results]
        colors = ['green' if fps > 25 else 'orange' if fps > 15 else 'red' for fps in fps_values]
        ax1.bar(resolutions, fps_values, color=colors, alpha=0.7)
        ax1.axhline(y=30, color='green', linestyle='--', alpha=0.5, label='ëª©í‘œ FPS (30)')
        ax1.set_ylabel('FPS', fontsize=11)
        ax1.set_title('í•´ìƒë„ë³„ FPS', fontsize=12, fontweight='bold')
        ax1.legend()
        ax1.grid(True, alpha=0.3, axis='y')
        
        # 2. ë“œë¡­ë¥  ë¹„êµ (ë§‰ëŒ€ ê·¸ë˜í”„)
        ax2 = fig.add_subplot(gs[0, 1])
        drop_rates = [r['drop_rate'] for r in results]
        colors_drop = ['green' if d < 5 else 'orange' if d < 15 else 'red' for d in drop_rates]
        ax2.bar(resolutions, drop_rates, color=colors_drop, alpha=0.7)
        ax2.axhline(y=5, color='green', linestyle='--', alpha=0.5, label='í—ˆìš© ë²”ìœ„ (5%)')
        ax2.set_ylabel('ë“œë¡­ë¥  (%)', fontsize=11)
        ax2.set_title('í•´ìƒë„ë³„ í”„ë ˆì„ ë“œë¡­ë¥ ', fontsize=12, fontweight='bold')
        ax2.legend()
        ax2.grid(True, alpha=0.3, axis='y')
        
        # 3. GPU ì‚¬ìš©ë¥  ë¹„êµ (ë§‰ëŒ€ ê·¸ë˜í”„)
        ax3 = fig.add_subplot(gs[0, 2])
        gpu_utils = [r['gpu_util'] for r in results]
        colors_gpu = ['orange' if g < 70 else 'green' if g < 90 else 'red' for g in gpu_utils]
        ax3.bar(resolutions, gpu_utils, color=colors_gpu, alpha=0.7)
        ax3.axhline(y=85, color='green', linestyle='--', alpha=0.5, label='ëª©í‘œ ì‚¬ìš©ë¥  (85%)')
        ax3.set_ylabel('GPU ì‚¬ìš©ë¥  (%)', fontsize=11)
        ax3.set_title('í•´ìƒë„ë³„ GPU ì‚¬ìš©ë¥ ', fontsize=12, fontweight='bold')
        ax3.legend()
        ax3.grid(True, alpha=0.3, axis='y')
        
        # 4. ë ˆì´í„´ì‹œ ë¶„í¬ (ë°•ìŠ¤í”Œë¡¯)
        ax4 = fig.add_subplot(gs[1, 0])
        latency_data = [r['latencies'] for r in results if r['latencies']]
        if latency_data:
            latency_data_ms = [[l * 1000 for l in latencies] for latencies in latency_data]
            bp = ax4.boxplot(latency_data_ms, labels=resolutions, patch_artist=True)
            for patch in bp['boxes']:
                patch.set_facecolor('lightblue')
            ax4.axhline(y=100, color='green', linestyle='--', alpha=0.5, label='ëª©í‘œ ë ˆì´í„´ì‹œ (100ms)')
            ax4.set_ylabel('ë ˆì´í„´ì‹œ (ms)', fontsize=11)
            ax4.set_title('ë ˆì´í„´ì‹œ ë¶„í¬ (ì „ì†¡â†’ìˆ˜ì‹ )', fontsize=12, fontweight='bold')
            ax4.legend()
            ax4.grid(True, alpha=0.3, axis='y')
        
        # 5. ì¶”ë¡  ì‹œê°„ ë¶„í¬ (ë°•ìŠ¤í”Œë¡¯)
        ax5 = fig.add_subplot(gs[1, 1])
        inference_data = [r['inference_times'] for r in results if r['inference_times']]
        if inference_data:
            inference_data_ms = [[t * 1000 for t in times] for times in inference_data]
            bp2 = ax5.boxplot(inference_data_ms, labels=resolutions, patch_artist=True)
            for patch in bp2['boxes']:
                patch.set_facecolor('lightgreen')
            ax5.set_ylabel('ì¶”ë¡  ì‹œê°„ (ms)', fontsize=11)
            ax5.set_title('ì¶”ë¡  ì‹œê°„ ë¶„í¬ (ë°°ì¹˜)', fontsize=12, fontweight='bold')
            ax5.grid(True, alpha=0.3, axis='y')
        
        # 6. GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ë§‰ëŒ€ ê·¸ë˜í”„)
        ax6 = fig.add_subplot(gs[1, 2])
        gpu_mems = [r['gpu_mem'] for r in results]
        ax6.bar(resolutions, gpu_mems, color='purple', alpha=0.7)
        ax6.set_ylabel('GPU ë©”ëª¨ë¦¬ (MB)', fontsize=11)
        ax6.set_title('í•´ìƒë„ë³„ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰', fontsize=12, fontweight='bold')
        ax6.grid(True, alpha=0.3, axis='y')
        
        # 7. ë ˆì´í„´ì‹œ P95/P99 ë¹„êµ (ê·¸ë£¹ ë§‰ëŒ€)
        ax7 = fig.add_subplot(gs[2, 0])
        x = np.arange(len(resolutions))
        width = 0.35
        p95_values = [r['latency_p95'] for r in results]
        p99_values = [r['latency_p99'] for r in results]
        ax7.bar(x - width/2, p95_values, width, label='P95', color='orange', alpha=0.7)
        ax7.bar(x + width/2, p99_values, width, label='P99', color='red', alpha=0.7)
        ax7.set_ylabel('ë ˆì´í„´ì‹œ (ms)', fontsize=11)
        ax7.set_title('ë ˆì´í„´ì‹œ P95/P99 ë¹„êµ', fontsize=12, fontweight='bold')
        ax7.set_xticks(x)
        ax7.set_xticklabels(resolutions)
        ax7.legend()
        ax7.grid(True, alpha=0.3, axis='y')
        
        # 8. ì¶”ë¡  ì‹œê°„ P95/P99 ë¹„êµ (ê·¸ë£¹ ë§‰ëŒ€)
        ax8 = fig.add_subplot(gs[2, 1])
        inf_p95_values = [r['inference_p95'] for r in results]
        inf_p99_values = [r['inference_p99'] for r in results]
        ax8.bar(x - width/2, inf_p95_values, width, label='P95', color='lightblue', alpha=0.7)
        ax8.bar(x + width/2, inf_p99_values, width, label='P99', color='darkblue', alpha=0.7)
        ax8.set_ylabel('ì¶”ë¡  ì‹œê°„ (ms)', fontsize=11)
        ax8.set_title('ì¶”ë¡  ì‹œê°„ P95/P99 ë¹„êµ', fontsize=12, fontweight='bold')
        ax8.set_xticks(x)
        ax8.set_xticklabels(resolutions)
        ax8.legend()
        ax8.grid(True, alpha=0.3, axis='y')
        
        # 9. ì¢…í•© ì ìˆ˜ (ë ˆì´ë” ì°¨íŠ¸)
        ax9 = fig.add_subplot(gs[2, 2], projection='polar')
        
        # ì •ê·œí™”ëœ ì ìˆ˜ ê³„ì‚° (0-100)
        metrics = []
        for r in results:
            fps_score = min(r['fps'] / 30 * 100, 100)  # 30 FPS ê¸°ì¤€
            drop_score = max(100 - r['drop_rate'] * 10, 0)  # ë“œë¡­ë¥  ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
            latency_score = max(100 - r['latency_p95'] / 2, 0)  # 200ms ê¸°ì¤€
            gpu_score = r['gpu_util']  # ì´ë¯¸ 0-100
            
            metrics.append([fps_score, drop_score, latency_score, gpu_score])
        
        categories = ['FPS', 'ì•ˆì •ì„±', 'ì‘ë‹µì„±', 'GPUí™œìš©']
        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
        angles += angles[:1]
        
        for i, (res, metric) in enumerate(zip(resolutions, metrics)):
            values = metric + metric[:1]
            ax9.plot(angles, values, 'o-', linewidth=2, label=res)
            ax9.fill(angles, values, alpha=0.15)
        
        ax9.set_xticks(angles[:-1])
        ax9.set_xticklabels(categories, fontsize=10)
        ax9.set_ylim(0, 100)
        ax9.set_title('ì¢…í•© ì„±ëŠ¥ ì ìˆ˜', fontsize=12, fontweight='bold', pad=20)
        ax9.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
        ax9.grid(True)
        
        plt.suptitle('ê°€ìƒ í”¼íŒ… ì‹œìŠ¤í…œ ì¢…í•© ì„±ëŠ¥ ë¶„ì„', fontsize=16, fontweight='bold')
        
        # ì €ì¥
        output_path = os.path.join(current_dir, 'comprehensive_performance_result.png')
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"[í…ŒìŠ¤íŠ¸] ê·¸ë˜í”„ ì €ì¥: {output_path}")
        
        plt.show()
        
        return output_path


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    video_path = r"C:\Users\parkj\Desktop\ponggwi\source\basic.mp4"
    
    if not os.path.exists(video_path):
        print(f"[ERROR] ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return
    
    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
    print(f"[í…ŒìŠ¤íŠ¸] Device: {device}")
    
    if device == 'cpu':
        print("[WARNING] GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    
    # í…ŒìŠ¤í„° ìƒì„± ë° ì‹¤í–‰
    tester = ComprehensivePerformanceTester(video_path, device=device)
    results = tester.run_comprehensive_test()
    
    if results:
        print(f"\n[í…ŒìŠ¤íŠ¸] í…ŒìŠ¤íŠ¸ ì™„ë£Œ! {len(results)}ê°œ í•´ìƒë„ í…ŒìŠ¤íŠ¸ë¨")
        
        # ì‹œê°í™”
        graph_path = tester.visualize_comprehensive_results(results)
        print(f"\n[í…ŒìŠ¤íŠ¸] ì‹œê°í™” ì™„ë£Œ: {graph_path}")
        
        # JSON ì €ì¥
        json_path = os.path.join(current_dir, 'comprehensive_performance_result.json')
        
        # JSON ì§ë ¬í™”ë¥¼ ìœ„í•´ numpy ë°°ì—´ ì œê±°
        results_for_json = []
        for r in results:
            r_copy = r.copy()
            r_copy.pop('latencies', None)
            r_copy.pop('inference_times', None)
            r_copy.pop('gpu_stats', None)
            results_for_json.append(r_copy)
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(results_for_json, f, indent=2, ensure_ascii=False)
        
        print(f"[í…ŒìŠ¤íŠ¸] JSON ì €ì¥: {json_path}")


if __name__ == "__main__":
    main()
