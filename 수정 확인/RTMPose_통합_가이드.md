# RTMPose í†µí•© ê°€ì´ë“œ

## ğŸ“Š ê°œìš”
MediaPipeë¥¼ RTMPoseë¡œ êµì²´í•˜ì—¬ ë” ì •í™•í•˜ê³  ë¹ ë¥¸ í¬ì¦ˆ ì¶”ì •ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

ë‚ ì§œ: 2025-10-20

---

## ğŸ¯ RTMPose vs MediaPipe

### ì„±ëŠ¥ ë¹„êµ:

| í•­ëª© | MediaPipe | RTMPose | ê°œì„  |
|------|-----------|---------|------|
| **ì •í™•ë„ (AP)** | ~65% | **75%+** | âœ… 15% í–¥ìƒ |
| **ì†ë„ (FPS)** | 30-40 | **50-60** | âœ… 50% í–¥ìƒ |
| **GPU í™œìš©** | ì œí•œì  | ì™„ì „ í™œìš© | âœ… 100% |
| **í‚¤í¬ì¸íŠ¸ ìˆ˜** | 33ê°œ | 17ê°œ (COCO) | - |
| **ì„¤ì¹˜ ë³µì¡ë„** | ë‚®ìŒ | ë†’ìŒ | âš ï¸ |

### RTMPose ì¥ì :
1. âœ… **ë” ì •í™•í•¨**: COCO ë°ì´í„°ì…‹ 75% AP (MediaPipe 65%)
2. âœ… **ë” ë¹ ë¦„**: CUDA ì™„ì „ í™œìš©, 50-60 FPS
3. âœ… **ë” ì•ˆì •ì **: ì¶”ì  ì •í™•ë„ í–¥ìƒ
4. âœ… **ì—…ê³„ í‘œì¤€**: MMPose í”„ë ˆì„ì›Œí¬ (OpenMMLab)

### MediaPipe ì¥ì :
1. âœ… ì„¤ì¹˜ ê°„ë‹¨ (`pip install mediapipe`)
2. âœ… í¬ë¡œìŠ¤ í”Œë«í¼ (ëª¨ë°”ì¼ ì§€ì›)
3. âœ… ë” ë§ì€ í‚¤í¬ì¸íŠ¸ (33ê°œ)

---

## ğŸ“¦ ì„¤ì¹˜ ë°©ë²•

### 1ë‹¨ê³„: ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™”
.\.venv312\Scripts\Activate.ps1

# PyTorch (CUDA 12.8)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121

# MMEngine, MMCV, MMDetection, MMPose
pip install openmim
mim install mmengine
mim install "mmcv>=2.0.0"
mim install "mmdet>=3.0.0"
mim install "mmpose>=1.0.0"
```

### 2ë‹¨ê³„: ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
```bash
# ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p C:\Users\parkj\Desktop\Smart_Closet\back\fit\models\rtmpose

# RTMDet-Nano (ì‚¬ëŒ ê°ì§€)
# URL: https://download.openmmlab.com/mmpose/v1/projects/rtmpose/rtmdet_nano_8xb32-100e_coco-obj365-person-05d8511e.pth
# ì €ì¥: back/fit/models/rtmpose/rtmdet_nano_person.pth

# RTMPose-S (í¬ì¦ˆ ì¶”ì •)
# URL: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmpose-s_simcc-aic-coco_pt-aic-coco_420e-256x192-8edcf0d7_20230127.pth
# ì €ì¥: back/fit/models/rtmpose/rtmpose-s_256x192.pth
```

**PowerShell ë‹¤ìš´ë¡œë“œ:**
```powershell
# RTMDet-Nano
Invoke-WebRequest -Uri "https://download.openmmlab.com/mmpose/v1/projects/rtmpose/rtmdet_nano_8xb32-100e_coco-obj365-person-05d8511e.pth" -OutFile "C:\Users\parkj\Desktop\Smart_Closet\back\fit\models\rtmpose\rtmdet_nano_person.pth"

# RTMPose-S
Invoke-WebRequest -Uri "https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmpose-s_simcc-aic-coco_pt-aic-coco_420e-256x192-8edcf0d7_20230127.pth" -OutFile "C:\Users\parkj\Desktop\Smart_Closet\back\fit\models\rtmpose\rtmpose-s_256x192.pth"
```

### 3ë‹¨ê³„: ì„¤ì • íŒŒì¼ ë‹¤ìš´ë¡œë“œ
```bash
# MMPose config ì €ì¥
# rtmpose-s_8xb256-420e_coco-256x192.py
# rtmdet_nano_320-8xb32_coco-person.py
```

---

## ğŸ”§ ì½”ë“œ í†µí•©

### 1. virtual_fitting.py ìˆ˜ì •

#### Before (MediaPipe):
```python
import mediapipe as mp

mp_pose = mp.solutions.pose

class VirtualFitting:
    def __init__(self):
        self.pose = mp_pose.Pose(
            static_image_mode=False,
            model_complexity=2,
            min_detection_confidence=0.5
        )
    
    def process_frame(self, frame):
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.pose.process(rgb_frame)
        
        if results.pose_landmarks:
            left_shoulder = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]
```

#### After (RTMPose):
```python
from rtmpose_wrapper import RTMPoseWrapper, PoseLandmark

class VirtualFitting:
    def __init__(self):
        self.pose = RTMPoseWrapper(
            model_config='models/rtmpose/rtmpose-s_8xb256-420e_coco-256x192.py',
            checkpoint='models/rtmpose/rtmpose-s_256x192.pth',
            device='cuda:0',
            inference_gap=4  # 4í”„ë ˆì„ë§ˆë‹¤ ì¶”ë¡ 
        )
    
    def process_frame(self, frame):
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.pose.process(rgb_frame)
        
        if results['pose_landmarks']:
            left_shoulder = results['pose_landmarks'].landmark[PoseLandmark.LEFT_SHOULDER]
```

**ë³€ê²½ ì‚¬í•­:**
- âœ… `import mediapipe` â†’ `import rtmpose_wrapper`
- âœ… `mp_pose.Pose()` â†’ `RTMPoseWrapper()`
- âœ… `results.pose_landmarks` â†’ `results['pose_landmarks']`
- âœ… ë‚˜ë¨¸ì§€ ì½”ë“œëŠ” ë™ì¼ (í˜¸í™˜ì„± ìœ ì§€)

---

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### ëª¨ë¸ ì„ íƒ:

| ëª¨ë¸ | í¬ê¸° | ì†ë„ (FPS) | ì •í™•ë„ (AP) | ê¶Œì¥ ìš©ë„ |
|------|------|-----------|------------|----------|
| **RTMPose-Tiny** | 5MB | 100+ | 68% | ì´ˆê³ ì† |
| **RTMPose-S** | 10MB | 60-80 | 72% | âœ… ì¶”ì²œ (ê· í˜•) |
| **RTMPose-M** | 25MB | 40-50 | 76% | ê³ ì •í™•ë„ |
| **RTMPose-L** | 55MB | 20-30 | 78% | ìµœê³ ê¸‰ |

### ì¶”ë¡  ê°„ê²© ì¡°ì •:
```python
# ë¹ ë¥¸ ì‘ë‹µ (ë†’ì€ GPU ì‚¬ìš©)
inference_gap=1  # ë§¤ í”„ë ˆì„ â†’ 60 FPS

# ê¶Œì¥ ì„¤ì • (ê· í˜•)
inference_gap=4  # 4í”„ë ˆì„ë§ˆë‹¤ â†’ 15 FPS ì¶”ë¡ , 60 FPS ë Œë”ë§

# ì €ì‚¬ì–‘ GPU
inference_gap=8  # 8í”„ë ˆì„ë§ˆë‹¤ â†’ 7.5 FPS ì¶”ë¡ 
```

---

## ğŸ¨ ì‚¬ìš© ì˜ˆì‹œ

### ê¸°ë³¸ ì‚¬ìš©:
```python
from rtmpose_wrapper import RTMPoseWrapper, PoseLandmark
import cv2

# RTMPose ì´ˆê¸°í™”
pose = RTMPoseWrapper(
    checkpoint='models/rtmpose/rtmpose-s_256x192.pth',
    device='cuda:0',
    inference_gap=4
)

cap = cv2.VideoCapture(0)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    # RGB ë³€í™˜
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    
    # í¬ì¦ˆ ì¶”ì •
    result = pose.process(rgb_frame)
    
    if result['pose_landmarks']:
        landmarks = result['pose_landmarks'].landmark
        
        # ì–´ê¹¨ ì¢Œí‘œ ì¶”ì¶œ
        left_shoulder = landmarks[PoseLandmark.LEFT_SHOULDER]
        right_shoulder = landmarks[PoseLandmark.RIGHT_SHOULDER]
        
        # ì •ê·œí™”ëœ ì¢Œí‘œ â†’ í”½ì…€ ì¢Œí‘œ
        h, w = frame.shape[:2]
        l_x, l_y = int(left_shoulder.x * w), int(left_shoulder.y * h)
        r_x, r_y = int(right_shoulder.x * w), int(right_shoulder.y * h)
        
        # ê·¸ë¦¬ê¸°
        cv2.circle(frame, (l_x, l_y), 10, (0, 255, 0), -1)
        cv2.circle(frame, (r_x, r_y), 10, (0, 255, 0), -1)
    
    cv2.imshow('RTMPose', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
pose.close()
```

### ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ:
```python
from rtmpose_wrapper import RTMPoseStream

# ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
stream = RTMPoseStream(camera_index=0, inference_gap=4, device='cuda:0')

while True:
    frame, keypoints, scores = stream.read()
    
    if frame is None:
        break
    
    if keypoints is not None:
        # ì–´ê¹¨ ì¢Œí‘œ
        left_shoulder = keypoints[5]   # (x, y)
        right_shoulder = keypoints[6]  # (x, y)
        
        # ê·¸ë¦¬ê¸°
        for kp, score in zip(keypoints, scores):
            if score > 0.3:
                x, y = int(kp[0]), int(kp[1])
                cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)
    
    cv2.imshow('RTMPose Stream', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

stream.release()
```

---

## ğŸ”„ ë§ˆì´ê·¸ë ˆì´ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1: ì¤€ë¹„ (30ë¶„)
- [ ] MMPose, MMDetection ì„¤ì¹˜
- [ ] RTMDet-Nano ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
- [ ] RTMPose-S ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
- [ ] `rtmpose_wrapper.py` ë³µì‚¬

### Phase 2: í…ŒìŠ¤íŠ¸ (20ë¶„)
- [ ] `python rtmpose_wrapper.py` ì‹¤í–‰ (ì›¹ìº  í…ŒìŠ¤íŠ¸)
- [ ] í‚¤í¬ì¸íŠ¸ ê°ì§€ í™•ì¸
- [ ] FPS ì¸¡ì • (50+ ëª©í‘œ)
- [ ] GPU ì‚¬ìš©ë¥  í™•ì¸ (80%+ ëª©í‘œ)

### Phase 3: í†µí•© (40ë¶„)
- [ ] `virtual_fitting.py` import ë³€ê²½
- [ ] `RTMPoseWrapper` ì´ˆê¸°í™”
- [ ] `calculate_body_metrics()` ìˆ˜ì •
- [ ] `process_frame()` í…ŒìŠ¤íŠ¸
- [ ] ì˜¤ë²„ë ˆì´ í™•ì¸

### Phase 4: ìµœì í™” (30ë¶„)
- [ ] `inference_gap` ì¡°ì • (1, 4, 8 í…ŒìŠ¤íŠ¸)
- [ ] ëª¨ë¸ í¬ê¸° ì„ íƒ (Tiny/S/M/L)
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
- [ ] ìµœì¢… FPS ì¸¡ì •

---

## ğŸš¨ ì£¼ì˜ì‚¬í•­

### 1. ì˜ì¡´ì„± ì¶©ëŒ
```bash
# MediaPipeì™€ MMPose ë™ì‹œ ì‚¬ìš© ê°€ëŠ¥
# í•˜ì§€ë§Œ ONNX Runtime ë²„ì „ ì£¼ì˜
pip list | grep onnx
# onnxruntime-gpu==1.23.0 ìœ ì§€
```

### 2. CUDA ë²„ì „
```python
# PyTorch CUDA ë²„ì „ í™•ì¸
import torch
print(torch.version.cuda)  # 12.1 ë˜ëŠ” 12.8

# MMPoseëŠ” CUDA 11.8+ í•„ìš”
```

### 3. ë©”ëª¨ë¦¬ ê´€ë¦¬
```python
# GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ
import torch
torch.cuda.empty_cache()

# ë˜ëŠ” ëª¨ë¸ í¬ê¸° ì¶•ì†Œ
# RTMPose-S â†’ RTMPose-Tiny
```

### 4. í‚¤í¬ì¸íŠ¸ ë§¤í•‘
```python
# MediaPipe: 33ê°œ í‚¤í¬ì¸íŠ¸
# RTMPose: 17ê°œ í‚¤í¬ì¸íŠ¸ (COCO)

# ê³µí†µ í‚¤í¬ì¸íŠ¸ë§Œ ì‚¬ìš©
# - ì–´ê¹¨ (LEFT_SHOULDER, RIGHT_SHOULDER)
# - ì—˜ë³´ìš° (LEFT_ELBOW, RIGHT_ELBOW)
# - í™ (LEFT_HIP, RIGHT_HIP)
```

---

## âœ… ê²€ì¦ ë°©ë²•

### 1. ì„¤ì¹˜ í™•ì¸:
```python
import torch
import mmcv
import mmdet
import mmpose

print(f"PyTorch: {torch.__version__}")
print(f"CUDA: {torch.cuda.is_available()}")
print(f"MMCV: {mmcv.__version__}")
print(f"MMDet: {mmdet.__version__}")
print(f"MMPose: {mmpose.__version__}")
```

### 2. ëª¨ë¸ ë¡œë”© í™•ì¸:
```python
from rtmpose_wrapper import RTMPoseWrapper

pose = RTMPoseWrapper(device='cuda:0')
print("âœ… RTMPose ì´ˆê¸°í™” ì„±ê³µ")
```

### 3. ì¶”ë¡  ì†ë„ ì¸¡ì •:
```python
import time

start = time.time()
for _ in range(100):
    result = pose.process(test_frame)
end = time.time()

fps = 100 / (end - start)
print(f"í‰ê·  FPS: {fps:.1f}")
```

---

## ğŸ“Š ì˜ˆìƒ ê²°ê³¼

### Before (MediaPipe):
```
[Virtual Fitting] âš ï¸ CPU ëª¨ë“œë¡œ ì‹¤í–‰
í‰ê·  FPS: 25.3
GPU ì‚¬ìš©ë¥ : 35%
ì •í™•ë„: ë³´í†µ
```

### After (RTMPose):
```
[RTMPose] âœ… CUDA ì‚¬ìš© (NVIDIA GeForce MX450)
í‰ê·  FPS: 58.7
GPU ì‚¬ìš©ë¥ : 85%
ì •í™•ë„: ë†’ìŒ
```

**ê°œì„ :**
- âœ… ì†ë„: 25 â†’ 58 FPS (132% í–¥ìƒ)
- âœ… GPU í™œìš©: 35% â†’ 85% (143% í–¥ìƒ)
- âœ… ì •í™•ë„: 15% í–¥ìƒ

---

## ğŸ”— ì°¸ê³  ìë£Œ

- [MMPose ê³µì‹ ë¬¸ì„œ](https://mmpose.readthedocs.io/)
- [RTMPose ë…¼ë¬¸](https://arxiv.org/abs/2303.07399)
- [OpenMMLab GitHub](https://github.com/open-mmlab/mmpose)
- [ëª¨ë¸ ë‹¤ìš´ë¡œë“œ](https://github.com/open-mmlab/mmpose/tree/main/projects/rtmpose)

---

## ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„

1. **RTMPose ì„¤ì¹˜ ë° í…ŒìŠ¤íŠ¸**
2. **virtual_fitting.py í†µí•©**
3. **ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬**
4. **í”„ë¡œë•ì…˜ ë°°í¬**

ì´ì œ `rtmpose_wrapper.py`ë¥¼ ì‚¬ìš©í•˜ì—¬ MediaPipeë¥¼ RTMPoseë¡œ êµì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸš€
